
> [!def] 
> В качестве алгоритма обучения модели бинарной классификации можем взять `градиентный спуск`
> $$w_{t+1} = w_t - \alpha\Delta_wL,$$
> где $\alpha$ - шаг оптимизации - коэффициент, влияющий на скорость и устойчивость алгоритма.

> [!attention] 
> Разное $\alpha$ порождает разные алгоритмы, дающие разные результаты.

