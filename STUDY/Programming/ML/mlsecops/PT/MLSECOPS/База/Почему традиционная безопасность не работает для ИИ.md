> [!problem] 
> 1. **Логика модели формируется данными, а не кодом.** Уязвимости появляются не в коде, а в данных и обучениях.
> 2. **Классические сканеры не видят атак.** Микрошумы, пиксели и токены - скрытые, немаркированные манипуляции
> 3. **Модель - чёрный ящик**. Её легко шатать запросами, находя нестабильные зоны.
> 4. **Периметр исчез**. Доверие размазано по датасетам, open-source, моделям из интернета.
> 5. **Поведение модели меняется**. Переобучение = новая логика -> нужны постоянные тесты.

> [!security] 
> Безопасность ИИ - это не про стены, а про понимание того, как думает модели и где на неё можно воздействовать.
> 


