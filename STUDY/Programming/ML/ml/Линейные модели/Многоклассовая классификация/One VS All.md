
> [!idea] 
> Обучим **$K$ линейных классификаторов** $b_1(x),...,b_K(x)$ `выдающих оценки принадлежности классам` $1,...,K$ соответственно. В случае с линейными моделями эти классификаторы будут иметь вид: $$b_k(x) = sgn(\langle w_k,x \rangle + w_{0k}$$
> 
> Классификатор с номером $k$ будем обучать по выборке $(x_i,2\mathbb{I}[y_i=k]-1)_{i=1}^k$;
> То есть `мы учим классификатор отличать k-ый класс от всех остальных`

> [!finally] 
> Логично, чтобы итоговый классификатор выдавал класс, соответствующий самому уверенному из бинарных алгоритмов. Уверенность можно в каком-то смысле измерить с помощью значений линейных функций: $$a(x)=argmax_k(\langle w_k,x \rangle + w_{0k})$$

> [!example] 
> Давайте посмотрим, что даст этот подход применительно к нашему датасету. Обучим три линейных модели, отличающих один класс от остальных

![[Pasted image 20251223115346.png]]
Теперь сравним значения линейных функций
![[Pasted image 20251223115356.png]]
и для каждой точки выберем тот класс, которому соответствует большее значение, то есть самый «уверенный» классификатор:
![[Pasted image 20251223115405.png]]

> [!problem]
> Хочется сказать, что самый маленький класс «обидели».
> Проблема данного подхода заключается в том, что каждый из классификаторов $b_1(x),...,b_k(x)$ обучается на своей выборке, и значения линейных функций, $\langle w_k,x \rangle + w_{0k}$ могут иметь разные масштабы. Из-за этого сравнивать их будет неправильно.
> Но и нормировать тоже не всегда будет хорошим выходом, ведь, например, в случае с SVM веса перестанут являться решением задачи, поскольку нормировка их вообще-то изменит.

