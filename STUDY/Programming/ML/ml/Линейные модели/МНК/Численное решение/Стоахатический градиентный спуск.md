
> [!problem] 
> На каждом шаге **градиентного спуска** нам требуется выполнить весьма сложную вычислительную задачку вычисления **градиента** по всей выборке (O(ND)).

> [!idea] 
> Мы можем попробовать ограничивать эти вычисления, заменяя их на `оценку по подвыборке`. 
> 

Иными словами, переходя от $$L(w, X, y) = \frac{1}{N}\sum_{i=1}^{N}L(w,x_i,y_i)$$К $$\nabla_wL(w,X,y)\approx \frac{1}{B}\sum_{t=1}^{B}\nabla_wL(w,x_{i_t},y_{i_t})$$
> [!important]
> где B - размер `батча` (наша подвыборка)

