> [!hint]
> **Эффективное по памяти хранение токенов:**  
> Вместо хранения полного текста в некоторых случаях можно хранить его токенизированное представление:

```json
# Хранение ID токенов вместо текста для конфиденциальных данных
chunk_record = {
    "vector": [...],
    "token_ids": [101, 2054, 2003, 1996, 22219],  # Токенизированное представление
    "metadata": {
        "document_id": "doc_123",
        "offset_start": 500,
        "offset_end": 850
    }
}
```

> [!list]
> **Сценарии использования хранения токенов:**
> - приложения с повышенной конфиденциальностью
> - среды с ограниченным пространством
> - быстрые прототипы с контролируемыми словарями

> [!list]
> **Ограничения:**
> - токенизация зависит от конкретной модели
> - ограниченные возможности полнотекстового поиска
> - более сложная отладка